{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Rr8nGXQgGhiV",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title import dependencies\n",
        "import os\n",
        "import re\n",
        "import gc\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from scipy.sparse import coo_matrix\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Downloading and Analysis"
      ],
      "metadata": {
        "id": "-pQMKS8xwgQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download dataset from Kaggle\n",
        "import kagglehub\n",
        "\n",
        "path = \"/root/.cache/kagglehub/datasets/himanshuwagh/spotify-million/versions/1\"\n",
        "if not os.path.exists(path):\n",
        "  # Download latest version\n",
        "  path = kagglehub.dataset_download(\"himanshuwagh/spotify-million\")\n",
        "\n",
        "# contiene le slices del dataset: 1000 slice das 1000 playlist ciascuna\n",
        "data: str = os.path.join(path, \"data\")"
      ],
      "metadata": {
        "id": "7qxXTE6xGska"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title shuffle slices in a list and pick from them\n",
        "shuffled_slices = np.array(os.listdir(data))\n",
        "np.random.shuffle(shuffled_slices)"
      ],
      "metadata": {
        "id": "KZl7WOvAOQaj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_slices[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYvh7DdkeDjg",
        "outputId": "3a4afdcf-ed9b-41ba-b965-428d03663e65"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['mpd.slice.528000-528999.json', 'mpd.slice.920000-920999.json',\n",
              "       'mpd.slice.730000-730999.json'], dtype='<U28')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVD Approach"
      ],
      "metadata": {
        "id": "RDESyr5dxGX7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Handling"
      ],
      "metadata": {
        "id": "5BqlPLiGHGQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "million_df = pd.DataFrame()\n",
        "num_training_files = 500\n",
        "\n",
        "# Create an empty list to hold all rows as dictionaries\n",
        "data_list = []\n",
        "uri_to_info = dict()\n",
        "\n",
        "#for i, filename in tqdm(enumerate(sorted(os.listdir(data), key=extract_starting_number)[:num_training_files]), desc=\"Processing Slices\"):\n",
        "for i, filename in tqdm(enumerate(shuffled_slices[:num_training_files]), desc=\"Processing Slices\", total = num_training_files):\n",
        "    if filename.startswith(\"mpd.slice.\") and filename.endswith(\".json\"):\n",
        "        filepath = os.path.join(data, filename)\n",
        "\n",
        "        with open(filepath, \"r\", encoding=\"utf-8\") as jsonfile:\n",
        "            cur_slice = json.load(jsonfile)\n",
        "\n",
        "        # for playlist in tqdm(cur_slice[\"playlists\"], desc=\"Processing playlist...\"):\n",
        "        for playlist in cur_slice[\"playlists\"]:\n",
        "            playlist_id = playlist[\"pid\"]\n",
        "            # num_tracks = playlist[\"num_tracks\"]\n",
        "\n",
        "            # Collect data for the playlist\n",
        "            for track in playlist[\"tracks\"]:\n",
        "                data_list.append({\n",
        "                    \"playlist\": playlist_id,\n",
        "                    \"track\": track[\"track_uri\"][14:]  # remove 'spotify:track:'\n",
        "                })\n",
        "                if track[\"track_uri\"][14:] not in uri_to_info:\n",
        "                  uri_to_info[track[\"track_uri\"][14:]] = (track[\"artist_name\"], track[\"track_name\"])\n",
        "\n",
        "    # update every 30 files for speedup\n",
        "    if i%30 == 0:\n",
        "        new_data = pd.DataFrame(data_list)\n",
        "        data_list.clear()\n",
        "        million_df = pd.concat([million_df, new_data], ignore_index=True)\n",
        "\n",
        "# Convert the list of dictionaries into a DataFrame in one go\n",
        "# dumb_dataset = pd.DataFrame(data_list)\n",
        "new_data = pd.DataFrame(data_list)\n",
        "data_list = []\n",
        "million_df = pd.concat([million_df, new_data], ignore_index=True)\n",
        "\n",
        "million_df[\"playlist\"] = million_df[\"playlist\"].astype(\"int32\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix4fSvZPHIjN",
        "outputId": "38700f41-91c6-42a8-9cff-92b661233175"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Slices: 100%|██████████| 500/500 [06:06<00:00,  1.36it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QpCHcYCnVQ-",
        "outputId": "2fa162e7-b909-4ee8-d055-4c86e9af6318"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33170567, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "million_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8m7kd91dICA",
        "outputId": "94757655-6222-4735-9ef9-0d8662498e91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 33170567 entries, 0 to 33170566\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Dtype \n",
            "---  ------    ----- \n",
            " 0   playlist  int32 \n",
            " 1   track     object\n",
            "dtypes: int32(1), object(1)\n",
            "memory usage: 379.6+ MB\n"
          ]
        }
      ],
      "source": [
        "million_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YHOwOJbOdI0j",
        "outputId": "35cb43dc-94f7-4ff0-da45-d3179b929f20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   playlist                   track\n",
              "0    528000  5mmgfPAMIFIhlP2VneJc0G\n",
              "1    528000  40riOy7x9W7GXjyGp4pjAv\n",
              "2    528000  4efoEY8iDBzUqitjmNDhpN\n",
              "3    528000  0NqQmmLEN9rlnkh2JW0UIs\n",
              "4    528000  1MQCTOWVfy4PcuBXkBsHVB"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5e7ee8ae-fdc7-4f14-87bd-53725b04c8b9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>playlist</th>\n",
              "      <th>track</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>528000</td>\n",
              "      <td>5mmgfPAMIFIhlP2VneJc0G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>528000</td>\n",
              "      <td>40riOy7x9W7GXjyGp4pjAv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>528000</td>\n",
              "      <td>4efoEY8iDBzUqitjmNDhpN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>528000</td>\n",
              "      <td>0NqQmmLEN9rlnkh2JW0UIs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>528000</td>\n",
              "      <td>1MQCTOWVfy4PcuBXkBsHVB</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e7ee8ae-fdc7-4f14-87bd-53725b04c8b9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5e7ee8ae-fdc7-4f14-87bd-53725b04c8b9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5e7ee8ae-fdc7-4f14-87bd-53725b04c8b9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c58a2d4f-32ca-4d32-9445-65610f27ff1b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c58a2d4f-32ca-4d32-9445-65610f27ff1b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c58a2d4f-32ca-4d32-9445-65610f27ff1b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "million_df"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "million_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Y8SuQT-iS5yS"
      },
      "outputs": [],
      "source": [
        "# Count how many playlists each track appears in\n",
        "track_frequency = million_df.groupby(\"track\")[\"playlist\"].nunique()\n",
        "total_songs = len(track_frequency)\n",
        "\n",
        "# Convert to a DataFrame for easier handling\n",
        "track_frequency_df = track_frequency.reset_index().rename(columns={\"playlist\": \"playlist_count\"})\n",
        "\n",
        "# Total number of playlists\n",
        "# total_playlists = million_df[\"playlist_id\"].nunique()\n",
        "total_playlists = 1000*num_training_files\n",
        "\n",
        "# threshold\n",
        "threshold = int(total_playlists * 0.00005)\n",
        "\n",
        "# Filter tracks that appear in at least the threshold number of playlists\n",
        "popular_tracks = track_frequency_df[track_frequency_df[\"playlist_count\"] >= threshold]\n",
        "partial = len(popular_tracks)\n",
        "\n",
        "# Extract popular track IDs\n",
        "popular_track_ids = popular_tracks[\"track\"].tolist()\n",
        "\n",
        "# Filter the original dataset\n",
        "filtered_df = million_df[million_df[\"track\"].isin(popular_track_ids)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxbI3CjQnNll",
        "outputId": "d73d7f5d-efdd-4736-e27c-d3965292fb68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minumum number of playlists:  25\n",
            "Total songs:  1608601\n",
            "Songs that appear in at least 25 playlists:  119003\n",
            "Ratio: 0.07\n"
          ]
        }
      ],
      "source": [
        "print(\"Minumum number of playlists: \", threshold)\n",
        "ratio = partial / total_songs\n",
        "print(\"Total songs: \", total_songs)\n",
        "print(f\"Songs that appear in at least {threshold} playlists: \", partial)\n",
        "print(f\"Ratio: {ratio:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Songs with most appearences in playlists: \")\n",
        "for uri, playlist in zip(track_frequency_df.sort_values(\"playlist_count\", ascending=False).head()[\"track\"], track_frequency_df.sort_values(\"playlist_count\", ascending=False).head()[\"playlist_count\"]):\n",
        "  artist, name = uri_to_info[uri]\n",
        "  print(f\"{artist} - {name} (Appears in {playlist} playlists, {playlist/total_playlists:.2f}% of total playlist in the training set)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5DdHxCUmShH",
        "outputId": "ecfe78d0-6234-423f-9454-318ecb7c9fd1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Songs with most appearences in playlists: \n",
            "Kendrick Lamar - HUMBLE. (Appears in 22593 playlists, 0.05% of total playlist in the training set)\n",
            "Drake - One Dance (Appears in 20669 playlists, 0.04% of total playlist in the training set)\n",
            "DRAM - Broccoli (feat. Lil Yachty) (Appears in 20275 playlists, 0.04% of total playlist in the training set)\n",
            "The Chainsmokers - Closer (Appears in 20236 playlists, 0.04% of total playlist in the training set)\n",
            "Post Malone - Congratulations (Appears in 19674 playlists, 0.04% of total playlist in the training set)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeVcOGmhdj3_",
        "outputId": "27014f85-c357-44d2-b698-06c941a0061f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 28469745 entries, 1 to 33170566\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Dtype \n",
            "---  ------    ----- \n",
            " 0   playlist  int32 \n",
            " 1   track     object\n",
            "dtypes: int32(1), object(1)\n",
            "memory usage: 543.0+ MB\n"
          ]
        }
      ],
      "source": [
        "filtered_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUFqR4g2pAcb",
        "outputId": "d91131bb-b503-44e3-c12b-bf5b36ee0b04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28469745, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "filtered_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8DGS_xXnc7e",
        "outputId": "eb333141-2d96-43c1-8aef-a202eeeab1f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(497138, 119003)\n"
          ]
        }
      ],
      "source": [
        "# Make an explicit copy of filtered_df\n",
        "filtered_df = filtered_df.copy()\n",
        "\n",
        "# Map playlist_id and track_id to numerical indices\n",
        "playlist_id_to_idx = {id: idx for idx, id in enumerate(filtered_df[\"playlist\"].unique())}\n",
        "track_uri_to_idx = {uri: idx for idx, uri in enumerate(filtered_df[\"track\"].unique())}\n",
        "\n",
        "filtered_df[\"playlist_idx\"] = filtered_df[\"playlist\"].map(playlist_id_to_idx)\n",
        "filtered_df[\"track_idx\"] = filtered_df[\"track\"].map(track_uri_to_idx)\n",
        "\n",
        "# Create COO matrix\n",
        "rows = filtered_df[\"playlist_idx\"]\n",
        "cols = filtered_df[\"track_idx\"]\n",
        "data_list = np.ones(len(filtered_df))  # All entries are 1 since a track belongs to a playlist\n",
        "\n",
        "coo_rating_matrix = coo_matrix((data_list, (rows, cols)), shape=(len(playlist_id_to_idx), len(track_uri_to_idx)))\n",
        "print(coo_rating_matrix.shape)  # Output: (485376, 18857)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# per rendere il codice della funzione di valutazione come quello sopra\n",
        "num_tracks = coo_rating_matrix.shape[1]\n",
        "tracks = set(track_uri_to_idx.keys())"
      ],
      "metadata": {
        "id": "TWW_TB_ySr1U"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json.dump(uri_to_info, open(\"uri_to_info.json\", \"w\"))\n",
        "del(uri_to_info)\n",
        "del(million_df, track_frequency_df, filtered_df)\n",
        "del(rows, cols, data_list, new_data)\n",
        "del(popular_tracks, popular_track_ids)\n",
        "del(playlist_id_to_idx, track_frequency)\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLB0fidEHut9",
        "outputId": "825f6b78-afd6-4800-cd75-c628a421a25f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHO4kakPH24z",
        "outputId": "0aa84d46-90bc-4e09-af24-3faf022a5401"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "wJW3mVilLoJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ScipySVD():\n",
        "  def __init__(self, n_components, **kwargs):\n",
        "    self.n_components = n_components\n",
        "    self.kwargs = kwargs\n",
        "\n",
        "\n",
        "  def fit(self, X):\n",
        "    _, _, components_ = svds(X, self.n_components, **self.kwargs)\n",
        "    self.components_ = components_\n",
        "\n",
        "\n",
        "  def transform(self ,X):\n",
        "    return X @ self.components_.T"
      ],
      "metadata": {
        "id": "TXin71eMIPvV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svd_model = ScipySVD(600, random_state=42)\n",
        "\n",
        "svd_model.fit(coo_rating_matrix)"
      ],
      "metadata": {
        "id": "_5zwJS1cKbrf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation"
      ],
      "metadata": {
        "id": "Hg5WR4cdLOQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title metrics definition\n",
        "def precision_at_k(predicted_matrix, ground_truth_matrix, input_matrix, k):\n",
        "    \"\"\"\n",
        "    Calculate precision at k while excluding items that are already in the input matrix (playlist).\n",
        "\n",
        "    Args:\n",
        "    - predicted_matrix (np.ndarray): Matrix of predicted scores for each song in the playlist.\n",
        "    - ground_truth_matrix (np.ndarray): Ground truth matrix with binary values indicating relevant songs.\n",
        "    - input_matrix (np.ndarray): Matrix representing songs already in the playlist (binary).\n",
        "    - k (int): The number of top items to consider.\n",
        "\n",
        "    Returns:\n",
        "    - float: The average precision at k, excluding already present songs.\n",
        "    \"\"\"\n",
        "    # Ensure the matrices have the same shape\n",
        "    assert predicted_matrix.shape == ground_truth_matrix.shape == input_matrix.shape, \\\n",
        "        \"Shape mismatch between predicted_matrix, ground_truth_matrix, and input_matrix.\"\n",
        "\n",
        "    # Create a mask for already existing items (input matrix)\n",
        "    mask = input_matrix > 0  # 1 indicates the item is already in the playlist\n",
        "\n",
        "    # Mask the predicted scores for already existing items by setting them to -inf\n",
        "    masked_predictions = np.where(mask, -np.inf, predicted_matrix)\n",
        "\n",
        "    # Use argsort to get the indices of the top k predictions after masking\n",
        "    top_k_indices = np.argsort(masked_predictions, axis=1)[:, ::-1][:, :k]\n",
        "\n",
        "    # Extract relevant items in ground truth corresponding to the top k predictions\n",
        "    relevant_items = ground_truth_matrix[np.arange(ground_truth_matrix.shape[0])[:, None], top_k_indices]\n",
        "\n",
        "    # Calculate precision as the number of relevant items divided by k\n",
        "    precision_scores = np.sum(relevant_items, axis=1) / k\n",
        "\n",
        "    # Return the average precision\n",
        "    return np.mean(precision_scores)\n",
        "\n",
        "\n",
        "\n",
        "def recall_at_k(predicted_matrix, ground_truth_matrix, input_matrix, k):\n",
        "    # Mask the predictions where the input matrix has 1s (already in the playlist)\n",
        "    mask = input_matrix == 1\n",
        "    masked_predictions = np.where(mask, -np.inf, predicted_matrix)\n",
        "\n",
        "    # Get the indices of the top k predictions for each row after masking\n",
        "    top_k_indices = np.argsort(masked_predictions, axis=1)[:, -k:][:, ::-1]\n",
        "\n",
        "    # Gather the relevant items in ground truth corresponding to top k predictions\n",
        "    relevant_items = ground_truth_matrix[np.arange(ground_truth_matrix.shape[0])[:, None], top_k_indices]\n",
        "\n",
        "    # Calculate the recall for each playlist\n",
        "    total_relevant = np.sum(ground_truth_matrix, axis=1)  # Total relevant items per playlist\n",
        "\n",
        "    # Avoid division by zero: mask rows with no relevant items\n",
        "    recall_scores = np.sum(relevant_items, axis=1) / np.maximum(total_relevant, 1)\n",
        "\n",
        "    # Return the mean recall, ignoring rows with no relevant items\n",
        "    return np.mean(recall_scores[total_relevant > 0])\n",
        "\n",
        "\n",
        "\n",
        "def mean_reciprocal_rank(predicted_matrix, ground_truth_matrix, input_matrix):\n",
        "    reciprocal_ranks = []\n",
        "\n",
        "    # Iterate over each playlist (row in the matrix)\n",
        "    for pred_row, true_row, input_row in zip(predicted_matrix, ground_truth_matrix, input_matrix):\n",
        "        # Mask the predictions where the input matrix has 1s (already in the playlist)\n",
        "        mask = input_row == 1\n",
        "        masked_predictions = np.where(mask, -np.inf, pred_row)\n",
        "\n",
        "        # Get the indices sorted by predicted scores in descending order\n",
        "        sorted_indices = np.argsort(masked_predictions)[::-1]\n",
        "\n",
        "        # Find the rank of the first relevant item\n",
        "        found_relevant = False\n",
        "        for rank, index in enumerate(sorted_indices, start=1):\n",
        "            if true_row[index] == 1:  # If the item is relevant in the ground truth\n",
        "                reciprocal_ranks.append(1 / rank)\n",
        "                found_relevant = True\n",
        "                break\n",
        "\n",
        "        # If no relevant items were found, append 0\n",
        "        if not found_relevant:\n",
        "            reciprocal_ranks.append(0)\n",
        "\n",
        "    # Return the mean of the reciprocal ranks\n",
        "    return np.mean(reciprocal_ranks)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X_DF2313G_f3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title evaluating functions definition\n",
        "def evaluate_model_k_tracks_removed_df(model, k, num_valid_files=10):\n",
        "  \"\"\"\n",
        "  evaluate model processing a slice of playlists, 200 playlist at time to avoid\n",
        "  colab cpu overflow\n",
        "  \"\"\"\n",
        "\n",
        "  precision_at_10 = np.zeros(num_valid_files)\n",
        "  precision_at_5 = np.zeros(num_valid_files)\n",
        "  precision_at_2 = np.zeros(num_valid_files)\n",
        "  precision_at_1 = np.zeros(num_valid_files)\n",
        "\n",
        "  recall_at_10 = np.zeros(num_valid_files)\n",
        "  recall_at_5 = np.zeros(num_valid_files)\n",
        "  recall_at_2 = np.zeros(num_valid_files)\n",
        "  recall_at_1 = np.zeros(num_valid_files)\n",
        "\n",
        "  mrr = np.zeros(num_valid_files)\n",
        "\n",
        "  for file_idx, filename in enumerate(shuffled_slices[num_training_files:num_training_files+num_valid_files]):\n",
        "    correct_playlists = np.zeros((1000, num_tracks))\n",
        "    p_counter = -1\n",
        "    if filename.startswith(\"mpd.slice.\") and filename.endswith(\".json\"):\n",
        "      filepath = os.path.join(data, filename)\n",
        "\n",
        "      with open(filepath, \"r\", encoding=\"utf-8\") as jsonfile:\n",
        "        cur_slice = json.load(jsonfile)\n",
        "\n",
        "      for playlist in cur_slice[\"playlists\"]:\n",
        "        p_counter += 1\n",
        "\n",
        "        for track in playlist[\"tracks\"]:\n",
        "          track_uri = track[\"track_uri\"][14:]\n",
        "\n",
        "          if track_uri in tracks:\n",
        "            t_idx = track_uri_to_idx[track_uri]\n",
        "\n",
        "            correct_playlists[p_counter, t_idx] = 1\n",
        "\n",
        "\n",
        "    incomplete_playlists = np.copy(correct_playlists)\n",
        "\n",
        "    # Turn exactly k ones to zeros per row\n",
        "    for row in incomplete_playlists:\n",
        "      # Get the indices of `1`s in the current row\n",
        "      one_indices = np.where(row == 1)[0]\n",
        "\n",
        "      if len(one_indices) >= k:\n",
        "        indices_to_zero = np.random.choice(one_indices, size=k, replace=False)\n",
        "        row[indices_to_zero] = 0\n",
        "\n",
        "    n_iter = 5\n",
        "\n",
        "    cur_precision_at_10 = [0 for _ in range(n_iter)]\n",
        "    cur_precision_at_5 = [0 for _ in range(n_iter)]\n",
        "    cur_precision_at_2 = [0 for _ in range(n_iter)]\n",
        "    cur_precision_at_1 = [0 for _ in range(n_iter)]\n",
        "\n",
        "    cur_recall_at_10 = [0 for _ in range(n_iter)]\n",
        "    cur_recall_at_5 = [0 for _ in range(n_iter)]\n",
        "    cur_recall_at_2 = [0 for _ in range(n_iter)]\n",
        "    cur_recall_at_1 = [0 for _ in range(n_iter)]\n",
        "\n",
        "    cur_mrr = [0 for _ in range(n_iter)]\n",
        "\n",
        "    size_batch = 1000 // n_iter\n",
        "\n",
        "    for iter in range(n_iter):\n",
        "      input_matrix_iter = incomplete_playlists[size_batch*iter:size_batch*(iter+1), :]\n",
        "      P_new = model.transform(input_matrix_iter)\n",
        "\n",
        "      # Predici la matrice ricostruita per le nuove playlist\n",
        "      predicted_matrix = np.dot(P_new, model.components_)\n",
        "\n",
        "      ground_truth_matrix_iter = correct_playlists[size_batch*iter:size_batch*(iter+1), :]\n",
        "\n",
        "      cur_precision_at_10[iter] = precision_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 10)\n",
        "      cur_precision_at_5[iter] = precision_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 5)\n",
        "      cur_precision_at_2[iter] = precision_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 2)\n",
        "      cur_precision_at_1[iter] = precision_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 1)\n",
        "\n",
        "      cur_recall_at_10[iter] = recall_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 10)\n",
        "      cur_recall_at_5[iter] = recall_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 5)\n",
        "      cur_recall_at_2[iter] = recall_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 2)\n",
        "      cur_recall_at_1[iter] = recall_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 1)\n",
        "\n",
        "      cur_mrr[iter] = mean_reciprocal_rank(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter)\n",
        "\n",
        "    precision_at_10[file_idx] = np.mean(cur_precision_at_10)\n",
        "    precision_at_5[file_idx] = np.mean(cur_precision_at_5)\n",
        "    precision_at_2[file_idx] = np.mean(cur_precision_at_2)\n",
        "    precision_at_1[file_idx] = np.mean(cur_precision_at_1)\n",
        "    recall_at_10[file_idx] = np.mean(cur_recall_at_10)\n",
        "    recall_at_5[file_idx] = np.mean(cur_recall_at_5)\n",
        "    recall_at_2[file_idx] = np.mean(cur_recall_at_2)\n",
        "    recall_at_1[file_idx] = np.mean(cur_recall_at_1)\n",
        "    mrr[file_idx] = np.mean(cur_mrr)\n",
        "\n",
        "  print(\"Precision@10 = \",np.mean(precision_at_10))\n",
        "  print(\"Precision@5 = \",np.mean(precision_at_5))\n",
        "  print(\"Precision@2 = \",np.mean(precision_at_2))\n",
        "  print(\"Precision@1 = \",np.mean(precision_at_1))\n",
        "\n",
        "  print(\"Recall@10 = \",np.mean(recall_at_10))\n",
        "  print(\"Recall@5 = \",np.mean(recall_at_5))\n",
        "  print(\"Recall@2 = \",np.mean(recall_at_2))\n",
        "  print(\"Recall@1 = \",np.mean(recall_at_1))\n",
        "\n",
        "  print(\"MRR = \", np.mean(mrr))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_model_k_tracks_per_playlist(model, k, num_valid_files=10):\n",
        "  \"\"\"\n",
        "  evaluate model processing a slice of playlists, 200 playlist at time to avoid\n",
        "  colab cpu overflow\n",
        "  \"\"\"\n",
        "\n",
        "  # num_valid_files = 1000 - num_training_files\n",
        "  precision_at_10 = np.zeros(num_valid_files)\n",
        "  precision_at_5 = np.zeros(num_valid_files)\n",
        "  precision_at_2 = np.zeros(num_valid_files)\n",
        "  precision_at_1 = np.zeros(num_valid_files)\n",
        "\n",
        "  recall_at_10 = np.zeros(num_valid_files)\n",
        "  recall_at_5 = np.zeros(num_valid_files)\n",
        "  recall_at_2 = np.zeros(num_valid_files)\n",
        "  recall_at_1 = np.zeros(num_valid_files)\n",
        "\n",
        "  mrr = np.zeros(num_valid_files)\n",
        "\n",
        "  for file_idx, filename in enumerate(shuffled_slices[num_training_files:num_training_files+num_valid_files]):\n",
        "    correct_playlists = np.zeros((1000, num_tracks))\n",
        "    p_counter = -1\n",
        "    if filename.startswith(\"mpd.slice.\") and filename.endswith(\".json\"):\n",
        "      filepath = os.path.join(data, filename)\n",
        "\n",
        "      with open(filepath, \"r\", encoding=\"utf-8\") as jsonfile:\n",
        "        cur_slice = json.load(jsonfile)\n",
        "\n",
        "      for playlist in cur_slice[\"playlists\"]:\n",
        "        p_counter += 1\n",
        "\n",
        "        for track in playlist[\"tracks\"]:\n",
        "          track_uri = track[\"track_uri\"][14:]\n",
        "\n",
        "          if track_uri in tracks:\n",
        "            t_idx = track_uri_to_idx[track_uri]\n",
        "\n",
        "            correct_playlists[p_counter, t_idx] = 1\n",
        "\n",
        "\n",
        "    incomplete_playlists = np.copy(correct_playlists)\n",
        "\n",
        "    for row in incomplete_playlists:\n",
        "      one_indexes = np.where(row == 1)[0]\n",
        "\n",
        "      if len(one_indexes) >= k:\n",
        "        indices_to_zero = np.random.choice(one_indexes, size=(len(one_indexes)-k), replace=False)\n",
        "        row[indices_to_zero] = 0\n",
        "\n",
        "    n_iter = 5\n",
        "\n",
        "    cur_precision_at_10 = [0 for _ in range(n_iter)]\n",
        "    cur_precision_at_5 = [0 for _ in range(n_iter)]\n",
        "    cur_precision_at_2 = [0 for _ in range(n_iter)]\n",
        "    cur_precision_at_1 = [0 for _ in range(n_iter)]\n",
        "\n",
        "    cur_recall_at_10 = [0 for _ in range(n_iter)]\n",
        "    cur_recall_at_5 = [0 for _ in range(n_iter)]\n",
        "    cur_recall_at_2 = [0 for _ in range(n_iter)]\n",
        "    cur_recall_at_1 = [0 for _ in range(n_iter)]\n",
        "\n",
        "    cur_mrr = [0 for _ in range(n_iter)]\n",
        "\n",
        "    size_batch = 1000 // n_iter\n",
        "\n",
        "    for iter in range(n_iter):\n",
        "      input_matrix_iter = incomplete_playlists[size_batch*iter:size_batch*(iter+1), :]\n",
        "      P_new = model.transform(input_matrix_iter)\n",
        "\n",
        "      # Predici la matrice ricostruita per le nuove playlist\n",
        "      predicted_matrix = np.dot(P_new, model.components_)\n",
        "\n",
        "      ground_truth_matrix_iter = correct_playlists[size_batch*iter:size_batch*(iter+1), :]\n",
        "\n",
        "      cur_precision_at_10[iter] = precision_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 10)\n",
        "      cur_precision_at_5[iter] = precision_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 5)\n",
        "      cur_precision_at_2[iter] = precision_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 2)\n",
        "      cur_precision_at_1[iter] = precision_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 1)\n",
        "\n",
        "      cur_recall_at_10[iter] = recall_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 10)\n",
        "      cur_recall_at_5[iter] = recall_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 5)\n",
        "      cur_recall_at_2[iter] = recall_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 2)\n",
        "      cur_recall_at_1[iter] = recall_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 1)\n",
        "\n",
        "      cur_mrr[iter] = mean_reciprocal_rank(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter)\n",
        "\n",
        "    precision_at_10[file_idx] = np.mean(cur_precision_at_10)\n",
        "    precision_at_5[file_idx] = np.mean(cur_precision_at_5)\n",
        "    precision_at_2[file_idx] = np.mean(cur_precision_at_2)\n",
        "    precision_at_1[file_idx] = np.mean(cur_precision_at_1)\n",
        "    recall_at_10[file_idx] = np.mean(cur_recall_at_10)\n",
        "    recall_at_5[file_idx] = np.mean(cur_recall_at_5)\n",
        "    recall_at_2[file_idx] = np.mean(cur_recall_at_2)\n",
        "    recall_at_1[file_idx] = np.mean(cur_recall_at_1)\n",
        "    mrr[file_idx] = np.mean(cur_mrr)\n",
        "\n",
        "  print(\"Precision@10 = \",np.mean(precision_at_10))\n",
        "  print(\"Precision@5 = \",np.mean(precision_at_5))\n",
        "  print(\"Precision@2 = \",np.mean(precision_at_2))\n",
        "  print(\"Precision@1 = \",np.mean(precision_at_1))\n",
        "\n",
        "  print(\"Recall@10 = \",np.mean(recall_at_10))\n",
        "  print(\"Recall@5 = \",np.mean(recall_at_5))\n",
        "  print(\"Recall@2 = \",np.mean(recall_at_2))\n",
        "  print(\"Recall@1 = \",np.mean(recall_at_1))\n",
        "\n",
        "  print(\"MRR = \", np.mean(mrr))"
      ],
      "metadata": {
        "id": "EApnpa-aLSX2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K1 = [0, 2, 5, 15, 30]\n",
        "K2 = [2, 5, 15, 30]\n",
        "\n",
        "for k in K1:\n",
        "  print(f\"\\n Validation Metrics Removing {k} songs:\")\n",
        "  evaluate_model_k_tracks_removed_df(svd_model, k, 2)\n",
        "  print()\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "for k in K2:\n",
        "  print(f\"\\n Validation Metrics Keeping {k} songs per playlist:\")\n",
        "  evaluate_model_k_tracks_per_playlist(svd_model, k, 2)\n",
        "  print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "id": "4SuVi9BI_zQh",
        "outputId": "9ccdbc66-a487-4fd2-a008-eef1e25871f3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Metrics Removing 0 songs:\n",
            "Precision@10 =  0.0\n",
            "Precision@5 =  0.0\n",
            "Precision@2 =  0.0\n",
            "Precision@1 =  0.0\n",
            "Recall@10 =  0.0\n",
            "Recall@5 =  0.0\n",
            "Recall@2 =  0.0\n",
            "Recall@1 =  0.0\n",
            "MRR =  8.356552242550259e-06\n",
            "\n",
            "\n",
            " Validation Metrics Removing 2 songs:\n",
            "Precision@10 =  0.02195\n",
            "Precision@5 =  0.030100000000000002\n",
            "Precision@2 =  0.045\n",
            "Precision@1 =  0.055\n",
            "Recall@10 =  0.0075839094554543286\n",
            "Recall@5 =  0.0053664747477425705\n",
            "Recall@2 =  0.0032476814609948964\n",
            "Recall@1 =  0.0021008535765224415\n",
            "MRR =  0.10399879473686229\n",
            "\n",
            "\n",
            " Validation Metrics Removing 5 songs:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-353606d03dcd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mK1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n Validation Metrics Removing {k} songs:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mevaluate_model_k_tracks_removed_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvd_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-79bf3e4d47da>\u001b[0m in \u001b[0;36mevaluate_model_k_tracks_removed_df\u001b[0;34m(model, k, num_valid_files)\u001b[0m\n\u001b[1;32m     83\u001b[0m       \u001b[0mcur_recall_at_5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_at_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth_matrix_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_matrix_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m       \u001b[0mcur_recall_at_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_at_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth_matrix_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_matrix_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m       \u001b[0mcur_recall_at_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_at_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth_matrix_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_matrix_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m       \u001b[0mcur_mrr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_reciprocal_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth_matrix_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_matrix_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-d601fc13ba3a>\u001b[0m in \u001b[0;36mrecall_at_k\u001b[0;34m(predicted_matrix, ground_truth_matrix, input_matrix, k)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# Get the indices of the top k predictions for each row after masking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mtop_k_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# Gather the relevant items in ground truth corresponding to top k predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margsort\u001b[0;34m(a, axis, kind, order)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \"\"\"\n\u001b[0;32m-> 1133\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argsort'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Language Model Approach"
      ],
      "metadata": {
        "id": "o8buF6l80anu"
      }
    }
  ]
}