{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55dacc2c-5749-4862-813f-814f7fab4548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# import kagglehub\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import FileLink, display\n",
    "%matplotlib inline\n",
    "\n",
    "# --- Device ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# --- Data Loading ---\n",
    "# Impostiamo i parametri per il caricamento\n",
    "num_slices = 100      # numero di slice da caricare\n",
    "num_playlists = 1000   # numero di playlist per ogni slice\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f6e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specifica un percorso personalizzato (modifica secondo le tue esigenze)\n",
    "data_dir = \"data/\"\n",
    "# Scarica il file ZIP\n",
    "!gdown \"1jj_ApW79I2n2n4skXmXrNWVWroOlaEuM\" -O data_zipped.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cff9da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrai il contenuto nella directory specificata\n",
    "with zipfile.ZipFile(\"data_zipped.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(data_dir)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dc8915",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(data_dir, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b3a1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista dei file estratti nella cartella specificata\n",
    "slices = sorted(os.listdir(data_dir))[:num_slices]\n",
    "\n",
    "print(f\"Caricati {len(slices)} file dalla cartella '{data_dir}':\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599b1b2b-4deb-4e85-a4a1-de1d4410b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists = []\n",
    "for slice_file in slices:\n",
    "    with open(os.path.join(data_dir, slice_file), \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    # Aggiungiamo solo le prime num_playlists playlist per ogni slice\n",
    "    playlists.extend(data['playlists'][:num_playlists])\n",
    "\n",
    "# --- Preprocessing: estrazione della feature \"track_name\" ---\n",
    "playlists_tracks = [\n",
    "    [track['track_name'] for track in playlist['tracks']]\n",
    "    for playlist in playlists\n",
    "]\n",
    "\n",
    "# --- Costruzione del vocabolario ---\n",
    "unique_tracks = {track for playlist in playlists_tracks for track in playlist}\n",
    "if '.' in unique_tracks:\n",
    "    unique_tracks.remove('.')\n",
    "# Il token '.' (stop/start) avrà indice 0\n",
    "stoi = {track: i+1 for i, track in enumerate(sorted(unique_tracks))}\n",
    "stoi['.'] = 0\n",
    "itos = {i: track for track, i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(\"Vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fefb591-3f80-4307-9d30-6165175a7229",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Creazione del dataset per il language model ---\n",
    "block_size = 5  # lunghezza del contesto\n",
    "X_data, Y_data = [], []\n",
    "for playlist in playlists_tracks:\n",
    "    context = [0] * block_size  # inizializziamo il contesto con il token di stop\n",
    "    # Aggiungiamo il token di stop alla fine della playlist\n",
    "    for track in playlist + ['.']:\n",
    "        ix = stoi[track]\n",
    "        X_data.append(context.copy())\n",
    "        Y_data.append(ix)\n",
    "        # Aggiorniamo il contesto: shift a sinistra e aggiungiamo l'indice corrente\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "X = torch.tensor(X_data, dtype=torch.long)\n",
    "Y = torch.tensor(Y_data, dtype=torch.long)\n",
    "print(\"Dataset shape:\", X.shape, Y.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a18a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Suddivisione train/val/test ---\n",
    "indices = torch.randperm(X.shape[0])\n",
    "X = X[indices]\n",
    "Y = Y[indices]\n",
    "n_total = X.shape[0]\n",
    "n_train = int(0.8 * n_total)\n",
    "n_val   = int(0.1 * n_total)\n",
    "\n",
    "Xtr, Ytr = X[:n_train], Y[:n_train]\n",
    "Xval, Yval = X[n_train:n_train+n_val], Y[n_train:n_train+n_val]\n",
    "Xte, Yte = X[n_train+n_val:], Y[n_train+n_val:]\n",
    "print(\"Training samples:\", Xtr.shape[0])\n",
    "print(\"Validation samples:\", Xval.shape[0])\n",
    "print(\"Test samples:\", Xte.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6767d05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Definizione del modello ---\n",
    "class PlaylistModel(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embd, block_size, n_hidden):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, n_embd)\n",
    "        self.block_size = block_size\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(n_embd * block_size, n_hidden, bias=False),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hidden, n_hidden, bias=False),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hidden, n_hidden, bias=False),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hidden, n_hidden, bias=False),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hidden, n_hidden, bias=False),\n",
    "            nn.BatchNorm1d(n_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hidden, vocab_size, bias=False),\n",
    "            nn.BatchNorm1d(vocab_size)\n",
    "        )\n",
    "        # Riduciamo la scala del layer BN finale\n",
    "        final_bn = self.mlp[-1]\n",
    "        final_bn.weight.data.mul_(0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)                   # -> (batch_size, block_size, n_embd)\n",
    "        emb = emb.view(emb.size(0), -1)             # -> (batch_size, block_size * n_embd)\n",
    "        logits = self.mlp(emb)                      # -> (batch_size, vocab_size)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c146e431",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embd = 100\n",
    "n_hidden = 100\n",
    "model = PlaylistModel(vocab_size, n_embd, block_size, n_hidden).to(device)\n",
    "print(\"Numero di parametri:\", sum(p.numel() for p in model.parameters()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb21b8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Ottimizzatore e DataLoader ---\n",
    "batch_size = 64\n",
    "train_dataset = TensorDataset(Xtr, Ytr)\n",
    "val_dataset   = TensorDataset(Xval, Yval)\n",
    "test_dataset  = TensorDataset(Xte, Yte)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "numb_step_change = 1500\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_loss(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        logits = model(xb)\n",
    "        loss = F.cross_entropy(logits, yb, reduction='sum')\n",
    "        total_loss += loss.item()\n",
    "        total_samples += xb.size(0)\n",
    "    model.train()\n",
    "    return total_loss / total_samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f9ec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training ---\n",
    "max_steps = 2000\n",
    "log_interval = 100\n",
    "step = 0\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "steps_list = []\n",
    "\n",
    "model.train()\n",
    "\n",
    "while step < max_steps:\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = F.cross_entropy(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss_history.append(loss.item())\n",
    "        step += 1\n",
    "\n",
    "        if step == numb_step_change:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = 0.01\n",
    "\n",
    "        if step % log_interval == 0:\n",
    "            print('ok')\n",
    "            val_loss = evaluate_loss(val_loader)\n",
    "            steps_list.append(step)\n",
    "            val_loss_history.append(val_loss)\n",
    "            print(f'{step:7d}/{max_steps:7d}: Train loss = {loss.item():.4f}, Val loss = {val_loss:.4f}')\n",
    "\n",
    "        if step >= max_steps:\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f2c86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot di train e validation loss ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_loss_history, label=\"Train Loss\", alpha=0.6)\n",
    "plt.plot(steps_list, val_loss_history, 'ro-', label=\"Validation Loss\", markersize=5)\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")\n",
    "plt.title(\"Training e Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- Valutazione finale sui dataset ---\n",
    "print(\"Train Loss:\", evaluate_loss(train_loader))\n",
    "print(\"Val Loss:\", evaluate_loss(val_loader))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83c9191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Calcolo delle metriche sul test set ---\n",
    "k_values = [1, 2, 3, 5]\n",
    "model.eval()\n",
    "\n",
    "all_logits = []\n",
    "all_targets = []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        logits = model(xb)\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_targets.append(yb.cpu())\n",
    "all_logits = torch.cat(all_logits, dim=0)\n",
    "all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "test_loss = F.cross_entropy(all_logits, all_targets).item()\n",
    "print(\"Test Loss:\", test_loss)\n",
    "\n",
    "probs = F.softmax(all_logits, dim=1)\n",
    "ranking = torch.argsort(probs, dim=1, descending=True)\n",
    "\n",
    "precision_at_k = {k: 0.0 for k in k_values}\n",
    "recall_at_k = {k: 0.0 for k in k_values}\n",
    "N = all_targets.shape[0]\n",
    "\n",
    "for k in k_values:\n",
    "    topk = ranking[:, :k]\n",
    "    correct = (topk == all_targets.unsqueeze(1)).any(dim=1).float()\n",
    "    precision_at_k[k] = (correct / k).mean().item()\n",
    "    recall_at_k[k] = correct.mean().item()\n",
    "\n",
    "for k in k_values:\n",
    "    print(f\"Precision@{k}: {precision_at_k[k]:.4f}, Recall@{k}: {recall_at_k[k]:.4f}\")\n",
    "\n",
    "true_logits = all_logits[torch.arange(N), all_targets].unsqueeze(1)\n",
    "ranks = (all_logits >= true_logits).sum(dim=1).float()\n",
    "mrr = (1.0 / ranks).mean().item()\n",
    "print(f\"MRR: {mrr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5aa047",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "implementare hyperparameter tuning su n\\_embd, n\\_hidden e il batch size, \n",
    "dato che questi parametri controllano la capacità del modello e l’efficienza del training. \n",
    "Inizia definendo uno spazio di ricerca ragionevole (ad es. n\\_embd \\in \\{50, 100, 200, 300\\}, n\\_hidden \\in \\{100, 200, 300, 400\\}, batch size \\in \\{32, 64, 128\\}) \n",
    "e valuta l’adozione di tecniche come la grid search e random search. \n",
    "Utilizza un set di validazione affidabile e monitora sia il loss che le metriche specifiche del task (come Precision@k e MRR) per guidare le tue scelte.\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11568c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Salvataggio del modello trainato ---\n",
    "model_path = \"playlist_model.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(\"Modello salvato in:\", model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc4dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Creazione di un link per il download del file ---\n",
    "# Soluzione 1: usando IPython.display.FileLink\n",
    "print(\"Clicca sul link sottostante per scaricare il modello:\")\n",
    "display(FileLink(model_path))\n",
    "\n",
    "# Soluzione 2 (alternativa): se fossi in Google Colab, puoi usare:\n",
    "# from google.colab import files\n",
    "# files.download(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
