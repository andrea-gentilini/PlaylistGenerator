{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install torchvision torchaudio\n",
        "!pip install pytorch-lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bqu4cUFbGVFk",
        "outputId": "a27a3b0c-c333-461c-ae01-47d2c7aec12c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cpu)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cpu)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.5.1+cpu)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (2024.12.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->torchvision) (3.0.2)\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.5.1+cpu)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.12.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.12.2)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2022.5.0->pytorch-lightning)\n",
            "  Downloading aiohttp-3.11.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.5)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics>=0.7.0->pytorch-lightning) (1.26.4)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
            "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
            "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
            "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (24.3.0)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
            "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
            "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
            "  Downloading propcache-0.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
            "  Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n",
            "Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl (819 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.3/819.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Downloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.11.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
            "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading propcache-0.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: propcache, multidict, lightning-utilities, frozenlist, async-timeout, aiohappyeyeballs, yarl, aiosignal, torchmetrics, aiohttp, pytorch-lightning\n",
            "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 async-timeout-5.0.1 frozenlist-1.5.0 lightning-utilities-0.11.9 multidict-6.1.0 propcache-0.2.1 pytorch-lightning-2.5.0.post0 torchmetrics-1.6.1 yarl-1.18.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "B9MjJdTU0yBI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import kagglehub\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading and Preprocessing the Dataset"
      ],
      "metadata": {
        "id": "-q50PN1z-nrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download from Kaggle\n",
        "path = \"/root/.cache/kagglehub/datasets/himanshuwagh/spotify-million/versions/1\"\n",
        "if not os.path.exists(path):\n",
        "  path = kagglehub.dataset_download(\"himanshuwagh/spotify-million\")"
      ],
      "metadata": {
        "id": "MmblanR42Or8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fb74b87-8753-4807-d44b-55fcf4e3926c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/himanshuwagh/spotify-million?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.20G/5.20G [00:24<00:00, 229MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create a unique correspondence using integer indices\n",
        "MAX_SEQ_LEN = 30\n",
        "number_of_slices = 10 #@param {type:\"slider\", min:1, max:1000, step:1}\n",
        "visited = set()\n",
        "correspondence = {'0': {\"artist\": \"\", \"song\": \"\", \"uri\": \"\"}}\n",
        "inv_correspondence = dict()\n",
        "c = 1\n",
        "for i in tqdm(range(number_of_slices)):\n",
        "  first = 1000*i\n",
        "  data_url = os.path.join(path, \"data\" , f'mpd.slice.{first}-{first+999}.json')\n",
        "  with open(data_url) as f:\n",
        "    data = json.load(f)['playlists']\n",
        "    for playlist in data:\n",
        "      if len(playlist['tracks']) > MAX_SEQ_LEN:\n",
        "        for track in playlist['tracks']:\n",
        "          if track['track_uri'] not in visited:\n",
        "            correspondence[c] = {\"artist\": track['artist_name'], \"song\": track['track_name'], \"uri\": track[\"track_uri\"]}\n",
        "            inv_correspondence[track['track_uri']] = c\n",
        "            visited.add(track['track_uri'])\n",
        "            c += 1\n",
        "\n",
        "with open(\"correspondence.json\", 'w') as f:\n",
        "  json.dump(correspondence, f)\n",
        "\n",
        "#with open(\"inv_correspondence.json\", 'w') as f:\n",
        "#  json.dump(inv_correspondence, f)\n",
        "\n",
        "vocab_size = len(correspondence)\n",
        "print(\"Number of unique songs: \", len(correspondence))\n",
        "del correspondence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDGIvhdD3DCM",
        "outputId": "308a24b9-8987-49b5-a6f7-01c317d9daf6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  4.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique songs:  159816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_song_details(idx: str, correspondence = None):\n",
        "  if not correspondence:\n",
        "    with open(\"correspondence.json\") as f:\n",
        "      correspondence = json.load(f)\n",
        "      d = correspondence[idx]\n",
        "      del correspondence\n",
        "      return d\n",
        "  else:\n",
        "    return correspondence[idx]['artist'], correspondence[idx]['song'], correspondence[idx]['uri']"
      ],
      "metadata": {
        "id": "oDwXlnQ9Di89"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = \"1\"\n",
        "get_song_details(idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lF8jxm9gGpGp",
        "outputId": "96cf4113-7204-4df3-ae5a-e895adede8ba"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'artist': 'Missy Elliott',\n",
              " 'song': 'Lose Control (feat. Ciara & Fat Man Scoop)',\n",
              " 'uri': 'spotify:track:0UaMYEvWZi0ZqiDOoHU3YI'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Saving playlists as lists of indices\n",
        "!mkdir -p playlists\n",
        "\n",
        "for i in tqdm(range(number_of_slices)):\n",
        "  first = 1000*i\n",
        "  data_url = os.path.join(path, \"data\" , f'mpd.slice.{first}-{first+999}.json')\n",
        "  with open(data_url) as f:\n",
        "    data = json.load(f)['playlists']\n",
        "    for idx, playlist in enumerate(data):\n",
        "      filename = f\"playlist_{first+idx}.json\"\n",
        "      new_playlist = {'n_followers': playlist['num_followers'], 'tracks': []}\n",
        "      if len(playlist['tracks']) > MAX_SEQ_LEN:\n",
        "        for track in playlist['tracks']:\n",
        "          new_playlist['tracks'].append(inv_correspondence[track['track_uri']])\n",
        "\n",
        "\n",
        "      with open(os.path.join(\"playlists\", filename), 'w') as f:\n",
        "        json.dump(new_playlist, f)\n",
        "\n",
        "del new_playlist, inv_correspondence"
      ],
      "metadata": {
        "id": "yXh74Pnr4_yB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "733d133c-2795-4d5a-d1b5-d01eb1e236bd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:03<00:00,  3.03it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create torch dataset\n",
        "\n",
        "class PlaylistDataset(Dataset):\n",
        "  def __init__(self, root_dir, seq_len = MAX_SEQ_LEN):\n",
        "    self.root_dir = root_dir\n",
        "    self.seq_len = seq_len\n",
        "    self.url_playlists = []\n",
        "    self.len_original_playlist = []\n",
        "\n",
        "    for url in os.listdir(root_dir):\n",
        "      if url.endswith('.json'):\n",
        "        with open(os.path.join(root_dir, url)) as f:\n",
        "          playlist = json.load(f)\n",
        "          if len(playlist['tracks']) > seq_len:\n",
        "            self.url_playlists.append(url)\n",
        "            self.len_original_playlist.append(len(playlist['tracks']))\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    c = 0\n",
        "    for l in self.len_original_playlist:\n",
        "      c += l - (self.seq_len+1)\n",
        "    return c\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    for i in range(len(self.len_original_playlist)):\n",
        "      if idx < self.len_original_playlist[i] - (self.seq_len+1):\n",
        "        break\n",
        "      idx -= self.len_original_playlist[i] - (self.seq_len+1)\n",
        "\n",
        "    with open(os.path.join(self.root_dir, self.url_playlists[i])) as f:\n",
        "        playlist = json.load(f)\n",
        "\n",
        "    tracks = playlist['tracks'][idx:idx+self.seq_len+1]\n",
        "    #followers = playlist['n_followers']\n",
        "\n",
        "    return (\n",
        "        torch.tensor(tracks[:-1], dtype=torch.long),\n",
        "        torch.tensor(tracks[1:], dtype=torch.long)\n",
        "    )\n",
        "\n",
        "\n",
        "dataset = PlaylistDataset(\"playlists\")\n",
        "print(\"Number of playlists: \", len(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sF1TfmJJ_OiR",
        "outputId": "3ba46d6c-0f0a-421d-d8e3-d820ee883a8a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of playlists:  391846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abfSwjPMg3n6",
        "outputId": "46227a92-7752-49f4-f658-7e562ab440f8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([  9593,   4003,  30789,   7800,   1953,   1968,   1252,   3037,  30348,\n",
            "          5037,  19120,   6351,  25061,     76,   6144,  35270,  81174, 129902,\n",
            "         21891,  21533,  24380,  37468,   3998,  22627,  13884,   6183,   1946,\n",
            "          5576,  13075,  69779]), tensor([  4003,  30789,   7800,   1953,   1968,   1252,   3037,  30348,   5037,\n",
            "         19120,   6351,  25061,     76,   6144,  35270,  81174, 129902,  21891,\n",
            "         21533,  24380,  37468,   3998,  22627,  13884,   6183,   1946,   5576,\n",
            "         13075,  69779,   4215]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "\n",
        "NUM_WORKERS = 2\n",
        "VAL_FRACTION = 0.1\n",
        "TEST_FRACTION = 0.1\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "total_length = len(dataset)\n",
        "val_length = int(total_length * VAL_FRACTION)\n",
        "test_length = int(total_length * TEST_FRACTION)\n",
        "train_length = total_length - val_length - test_length\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_length, val_length, test_length])\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)"
      ],
      "metadata": {
        "id": "P9DDWU-AGDpB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "torch.set_float32_matmul_precision('medium')\n",
        "\n",
        "HIDDEN_SIZE = 128\n",
        "NUM_LAYERS = 4\n",
        "LR = 0.01\n",
        "\n",
        "class RNNModel(pl.LightningModule):\n",
        "  def __init__(self, vocab_size, hidden_size = HIDDEN_SIZE, num_layers = NUM_LAYERS):\n",
        "    super().__init__()\n",
        "    self.vocab_size = vocab_size\n",
        "    self.rnn = nn.LSTM(input_size=vocab_size,\n",
        "                       hidden_size=hidden_size,\n",
        "                       num_layers=num_layers,\n",
        "                       dropout=0.1,\n",
        "                       batch_first=True)\n",
        "    self.decoder = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "  def forward(self, x, hidden=None):\n",
        "      x = F.one_hot(x, num_classes=self.vocab_size).float()\n",
        "      output, hidden = self.rnn(x, hidden)\n",
        "      output = self.decoder(output)\n",
        "      return output, hidden\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "      optimizer = torch.optim.Adam(self.parameters(), lr=LR)\n",
        "      return optimizer\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "      x, y = batch\n",
        "      y_hat, _ = self.forward(x)\n",
        "      y_hat = y_hat.squeeze()\n",
        "      loss = F.cross_entropy(y_hat.transpose(1, 2), y)\n",
        "      self.log('train_loss', loss)\n",
        "      return loss\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "      x, y = batch\n",
        "      y_hat, _ = self.forward(x)\n",
        "      loss = F.cross_entropy(y_hat.transpose(1, 2), y)\n",
        "      self.log('val_loss', loss)\n",
        "      return loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjKwkEi7Q0SL",
        "outputId": "15ea00f4-7a05-41c7-b957-02f8524ff0c5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_xla/__init__.py:253: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "\n",
        "MAX_EPOCHS = 10\n",
        "PATIENCE = 2\n",
        "\n",
        "early_stop_callback = EarlyStopping(monitor = 'val_loss', patience = PATIENCE, verbose = True, mode = 'min')\n",
        "model = RNNModel(vocab_size=vocab_size)\n",
        "\n",
        "trainer = pl.Trainer(max_epochs=MAX_EPOCHS, callbacks=[early_stop_callback])\n",
        "\n",
        "trainer.fit(model, train_loader, val_loader)"
      ],
      "metadata": {
        "id": "F7Y6S4ANUc5a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}