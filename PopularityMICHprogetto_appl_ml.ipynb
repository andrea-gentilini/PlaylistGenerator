{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Rr8nGXQgGhiV",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title import dependencies\n",
        "import os\n",
        "import re\n",
        "import gc\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from scipy.sparse import coo_matrix\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Downloading and Analysis"
      ],
      "metadata": {
        "id": "-pQMKS8xwgQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download dataset from Kaggle\n",
        "import kagglehub\n",
        "\n",
        "path = \"/root/.cache/kagglehub/datasets/himanshuwagh/spotify-million/versions/1\"\n",
        "if not os.path.exists(path):\n",
        "  # Download latest version\n",
        "  path = kagglehub.dataset_download(\"himanshuwagh/spotify-million\")\n",
        "\n",
        "# contiene le slices del dataset: 1000 slice das 1000 playlist ciascuna\n",
        "data: str = os.path.join(path, \"data\")"
      ],
      "metadata": {
        "id": "7qxXTE6xGska"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title shuffle slices in a list and pick from them\n",
        "shuffled_slices = np.array(os.listdir(data))\n",
        "np.random.shuffle(shuffled_slices)"
      ],
      "metadata": {
        "id": "KZl7WOvAOQaj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_slices[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYvh7DdkeDjg",
        "outputId": "ef5ee331-9f18-45c3-cf10-e404ca6bdd04"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['mpd.slice.756000-756999.json', 'mpd.slice.949000-949999.json',\n",
              "       'mpd.slice.953000-953999.json'], dtype='<U28')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVD Approach"
      ],
      "metadata": {
        "id": "RDESyr5dxGX7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Handling"
      ],
      "metadata": {
        "id": "5BqlPLiGHGQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "million_df = pd.DataFrame()\n",
        "num_training_files = 500\n",
        "\n",
        "# Create an empty list to hold all rows as dictionaries\n",
        "data_list = []\n",
        "uri_to_info = dict()\n",
        "playlist_to_follower = dict()\n",
        "\n",
        "#for i, filename in tqdm(enumerate(sorted(os.listdir(data), key=extract_starting_number)[:num_training_files]), desc=\"Processing Slices\"):\n",
        "for i, filename in tqdm(enumerate(shuffled_slices[:num_training_files]), desc=\"Processing Slices\", total = num_training_files):\n",
        "    if filename.startswith(\"mpd.slice.\") and filename.endswith(\".json\"):\n",
        "        filepath = os.path.join(data, filename)\n",
        "\n",
        "        with open(filepath, \"r\", encoding=\"utf-8\") as jsonfile:\n",
        "            cur_slice = json.load(jsonfile)\n",
        "\n",
        "        # for playlist in tqdm(cur_slice[\"playlists\"], desc=\"Processing playlist...\"):\n",
        "        for playlist in cur_slice[\"playlists\"]:\n",
        "            playlist_id = playlist[\"pid\"]\n",
        "            if not playlist_id in playlist_to_follower:\n",
        "              playlist_to_follower[playlist_id] = playlist[\"num_followers\"]\n",
        "\n",
        "            # Collect data for the playlist\n",
        "            for track in playlist[\"tracks\"]:\n",
        "                data_list.append({\n",
        "                    \"playlist\": playlist_id,\n",
        "                    \"track\": track[\"track_uri\"][14:]  # remove 'spotify:track:'\n",
        "                })\n",
        "                if track[\"track_uri\"][14:] not in uri_to_info:\n",
        "                  uri_to_info[track[\"track_uri\"][14:]] = (track[\"artist_name\"], track[\"track_name\"])\n",
        "\n",
        "    # update every 30 files for speedup\n",
        "    if i%30 == 0:\n",
        "        new_data = pd.DataFrame(data_list)\n",
        "        data_list.clear()\n",
        "        million_df = pd.concat([million_df, new_data], ignore_index=True)\n",
        "\n",
        "# Convert the list of dictionaries into a DataFrame in one go\n",
        "# dumb_dataset = pd.DataFrame(data_list)\n",
        "new_data = pd.DataFrame(data_list)\n",
        "data_list = []\n",
        "million_df = pd.concat([million_df, new_data], ignore_index=True)\n",
        "\n",
        "million_df[\"playlist\"] = million_df[\"playlist\"].astype(\"int32\")\n",
        "\n",
        "max_followers = max(playlist_to_follower.values())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix4fSvZPHIjN",
        "outputId": "51a04174-4c9f-43ca-8d53-c1f5d80c5a70"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Slices: 100%|██████████| 500/500 [05:26<00:00,  1.53it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QpCHcYCnVQ-",
        "outputId": "60e6e1dc-4e78-4927-94eb-95eff968b7b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33175700, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "million_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8m7kd91dICA",
        "outputId": "731b0178-c0c2-4f78-cd7b-9e368dac02ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 33175700 entries, 0 to 33175699\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Dtype \n",
            "---  ------    ----- \n",
            " 0   playlist  int32 \n",
            " 1   track     object\n",
            "dtypes: int32(1), object(1)\n",
            "memory usage: 379.7+ MB\n"
          ]
        }
      ],
      "source": [
        "million_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YHOwOJbOdI0j",
        "outputId": "70f0697b-d819-4979-d379-02c50809ec5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   playlist                   track\n",
              "0    756000  6otqZiIqqzzzggZdd1rKgO\n",
              "1    756000  5mkGfmJGFZpwK9nA5amOhv\n",
              "2    756000  73fzhVcs7n1wZz84eoE2vs\n",
              "3    756000  4GiVcDqNQI0fc0yYuRGH9m\n",
              "4    756000  0uppYCG86ajpV2hSR3dJJ0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4016e4a9-2872-4929-a890-e90df8ee5f81\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>playlist</th>\n",
              "      <th>track</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>756000</td>\n",
              "      <td>6otqZiIqqzzzggZdd1rKgO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>756000</td>\n",
              "      <td>5mkGfmJGFZpwK9nA5amOhv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>756000</td>\n",
              "      <td>73fzhVcs7n1wZz84eoE2vs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>756000</td>\n",
              "      <td>4GiVcDqNQI0fc0yYuRGH9m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>756000</td>\n",
              "      <td>0uppYCG86ajpV2hSR3dJJ0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4016e4a9-2872-4929-a890-e90df8ee5f81')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4016e4a9-2872-4929-a890-e90df8ee5f81 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4016e4a9-2872-4929-a890-e90df8ee5f81');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-56bda0a3-11d5-4869-b4c3-9c7b322e1d9b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-56bda0a3-11d5-4869-b4c3-9c7b322e1d9b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-56bda0a3-11d5-4869-b4c3-9c7b322e1d9b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "million_df"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "million_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Y8SuQT-iS5yS"
      },
      "outputs": [],
      "source": [
        "uri_to_appeareance = dict()\n",
        "\n",
        "# Count how many playlists each track appears in\n",
        "track_frequency = million_df.groupby(\"track\")[\"playlist\"].nunique()\n",
        "total_songs = len(track_frequency)\n",
        "\n",
        "# Convert to a DataFrame for easier handling\n",
        "track_frequency_df = track_frequency.reset_index().rename(columns={\"playlist\": \"playlist_count\"})\n",
        "\n",
        "# Total number of playlists\n",
        "# total_playlists = million_df[\"playlist_id\"].nunique()\n",
        "total_playlists = 1000*num_training_files\n",
        "\n",
        "# threshold\n",
        "threshold = int(total_playlists * 0.00005)\n",
        "\n",
        "# Filter tracks that appear in at least the threshold number of playlists\n",
        "popular_tracks = track_frequency_df[track_frequency_df[\"playlist_count\"] >= threshold]\n",
        "partial = len(popular_tracks)\n",
        "\n",
        "for uri, a in zip(popular_tracks[\"track\"], popular_tracks[\"playlist_count\"]):\n",
        "  if uri not in uri_to_appeareance:\n",
        "    uri_to_appeareance[uri] = a\n",
        "\n",
        "\n",
        "# Extract popular track IDs\n",
        "popular_track_ids = popular_tracks[\"track\"].tolist()\n",
        "\n",
        "# Filter the original dataset\n",
        "filtered_df = million_df[million_df[\"track\"].isin(popular_track_ids)]\n",
        "\n",
        "max_appeareance = max(uri_to_appeareance.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxbI3CjQnNll",
        "outputId": "5a3c2c28-e02f-4d2d-93b9-d10d02e31087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minumum number of playlists:  25\n",
            "Total songs:  1604875\n",
            "Songs that appear in at least 25 playlists:  118776\n",
            "Ratio: 0.07\n"
          ]
        }
      ],
      "source": [
        "print(\"Minumum number of playlists: \", threshold)\n",
        "ratio = partial / total_songs\n",
        "print(\"Total songs: \", total_songs)\n",
        "print(f\"Songs that appear in at least {threshold} playlists: \", partial)\n",
        "print(f\"Ratio: {ratio:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Songs with most appearences in playlists: \")\n",
        "for uri, playlist in zip(track_frequency_df.sort_values(\"playlist_count\", ascending=False).head()[\"track\"], track_frequency_df.sort_values(\"playlist_count\", ascending=False).head()[\"playlist_count\"]):\n",
        "  artist, name = uri_to_info[uri]\n",
        "  print(f\"{artist} - {name} (Appears in {playlist} playlists, {playlist/total_playlists:.2f}% of total playlist in the training set)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5DdHxCUmShH",
        "outputId": "ce79450b-bcf8-42fa-b700-07623adc273f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Songs with most appearences in playlists: \n",
            "Kendrick Lamar - HUMBLE. (Appears in 22686 playlists, 0.05% of total playlist in the training set)\n",
            "Drake - One Dance (Appears in 20797 playlists, 0.04% of total playlist in the training set)\n",
            "DRAM - Broccoli (feat. Lil Yachty) (Appears in 20438 playlists, 0.04% of total playlist in the training set)\n",
            "The Chainsmokers - Closer (Appears in 20277 playlists, 0.04% of total playlist in the training set)\n",
            "Post Malone - Congratulations (Appears in 19884 playlists, 0.04% of total playlist in the training set)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeVcOGmhdj3_",
        "outputId": "07e2430d-61c3-4e15-a0c4-fdd575d91291"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 28475584 entries, 0 to 33175699\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Dtype \n",
            "---  ------    ----- \n",
            " 0   playlist  int32 \n",
            " 1   track     object\n",
            "dtypes: int32(1), object(1)\n",
            "memory usage: 543.1+ MB\n"
          ]
        }
      ],
      "source": [
        "filtered_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUFqR4g2pAcb",
        "outputId": "a13d715b-9612-4e97-c24e-19f0c9d58fc1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28475584, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "filtered_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "s8DGS_xXnc7e",
        "outputId": "c56c966d-965f-4ff9-eab2-362614a085b5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'filtered_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-54659b1ee30e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Make an explicit copy of filtered_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mfiltered_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Map playlist_id and track_id to numerical indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'filtered_df' is not defined"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "# Make an explicit copy of filtered_df\n",
        "filtered_df = filtered_df.copy()\n",
        "\n",
        "# Map playlist_id and track_id to numerical indices\n",
        "playlist_id_to_idx = {id: idx for idx, id in enumerate(filtered_df[\"playlist\"].unique())}\n",
        "track_uri_to_idx = {uri: idx for idx, uri in enumerate(filtered_df[\"track\"].unique())}\n",
        "\n",
        "filtered_df[\"playlist_idx\"] = filtered_df[\"playlist\"].map(playlist_id_to_idx)\n",
        "filtered_df[\"track_idx\"] = filtered_df[\"track\"].map(track_uri_to_idx)\n",
        "\n",
        "# Create COO matrix\n",
        "rows = filtered_df[\"playlist_idx\"]\n",
        "cols = filtered_df[\"track_idx\"]\n",
        "data_list = np.ones(len(filtered_df))  # All entries are 1 since a track belongs to a playlist\n",
        "\n",
        "coo_rating_matrix = coo_matrix((data_list, (rows, cols)), shape=(len(playlist_id_to_idx), len(track_uri_to_idx)))\n",
        "print(coo_rating_matrix.shape)  # Output: (485376, 18857)\n",
        "\"\"\"\n",
        "\n",
        "# Make an explicit copy of filtered_df\n",
        "filtered_df = filtered_df.copy()\n",
        "\n",
        "# Map playlist_id and track_id to numerical indices\n",
        "playlist_id_to_idx = {id: idx for idx, id in enumerate(filtered_df[\"playlist\"].unique())}\n",
        "playlist_idx_to_id = {idx: id for id, idx in playlist_id_to_idx.items()}\n",
        "track_uri_to_idx = {uri: idx for idx, uri in enumerate(filtered_df[\"track\"].unique())}\n",
        "track_idx_to_uri = {idx: uri for uri, idx in track_uri_to_idx.items()}\n",
        "\n",
        "\n",
        "filtered_df[\"playlist_idx\"] = filtered_df[\"playlist\"].map(playlist_id_to_idx)\n",
        "filtered_df[\"track_idx\"] = filtered_df[\"track\"].map(track_uri_to_idx)\n",
        "\n",
        "# Create COO matrix\n",
        "rows = filtered_df[\"playlist_idx\"]\n",
        "cols = filtered_df[\"track_idx\"]\n",
        "\n",
        "coo_rating_matrix = np.zeros((len(playlist_id_to_idx), len(track_uri_to_idx)))\n",
        "for playlist_idx, track_idx in zip(rows, cols):\n",
        "  alpha, beta = 10, 5\n",
        "  song_popularity = uri_to_appeareance[track_idx_to_uri[track_idx]] / max_appeareance\n",
        "  playlist_popularity = playlist_to_follower[playlist_idx_to_id[playlist_idx]] / max_followers\n",
        "  coo_rating_matrix[playlist_idx, track_idx] = alpha*song_popularity + beta*playlist_popularity\n",
        "\n",
        "print(coo_rating_matrix.shape)  # Output: (485376, 18857)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# per rendere il codice della funzione di valutazione come quello sopra\n",
        "num_tracks = coo_rating_matrix.shape[1]\n",
        "tracks = set(track_uri_to_idx.keys())"
      ],
      "metadata": {
        "id": "TWW_TB_ySr1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json.dump(uri_to_info, open(\"uri_to_info.json\", \"w\"))\n",
        "json.dump(track_idx_to_uri, open(\"track_idx_to_uri.json\", \"w\"))\n",
        "del(playlist_idx_to_id, track_idx_to_uri)\n",
        "del(uri_to_info)\n",
        "del(million_df, track_frequency_df, filtered_df)\n",
        "del(rows, cols, data_list, new_data)\n",
        "del(popular_tracks, popular_track_ids)\n",
        "del(playlist_id_to_idx, track_frequency)\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "mLB0fidEHut9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "id": "mHO4kakPH24z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "wJW3mVilLoJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ScipySVD():\n",
        "  def __init__(self, n_components, **kwargs):\n",
        "    self.n_components = n_components\n",
        "    self.kwargs = kwargs\n",
        "\n",
        "\n",
        "  def fit(self, X):\n",
        "    _, _, components_ = svds(X, self.n_components, **self.kwargs)\n",
        "    self.components_ = components_\n",
        "\n",
        "\n",
        "  def transform(self ,X):\n",
        "    return X @ self.components_.T"
      ],
      "metadata": {
        "id": "TXin71eMIPvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svd_model = ScipySVD(600, random_state=42)\n",
        "\n",
        "svd_model.fit(coo_rating_matrix)"
      ],
      "metadata": {
        "id": "_5zwJS1cKbrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation"
      ],
      "metadata": {
        "id": "Hg5WR4cdLOQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title metrics definition\n",
        "def precision_at_k(predicted_matrix, ground_truth_matrix, input_matrix, k):\n",
        "    \"\"\"\n",
        "    Calculate precision at k while excluding items that are already in the input matrix (playlist).\n",
        "\n",
        "    Args:\n",
        "    - predicted_matrix (np.ndarray): Matrix of predicted scores for each song in the playlist.\n",
        "    - ground_truth_matrix (np.ndarray): Ground truth matrix with binary values indicating relevant songs.\n",
        "    - input_matrix (np.ndarray): Matrix representing songs already in the playlist (binary).\n",
        "    - k (int): The number of top items to consider.\n",
        "\n",
        "    Returns:\n",
        "    - float: The average precision at k, excluding already present songs.\n",
        "    \"\"\"\n",
        "    # Ensure the matrices have the same shape\n",
        "    assert predicted_matrix.shape == ground_truth_matrix.shape == input_matrix.shape, \\\n",
        "        \"Shape mismatch between predicted_matrix, ground_truth_matrix, and input_matrix.\"\n",
        "\n",
        "    # Create a mask for already existing items (input matrix)\n",
        "    mask = input_matrix > 0  # 1 indicates the item is already in the playlist\n",
        "\n",
        "    # Mask the predicted scores for already existing items by setting them to -inf\n",
        "    masked_predictions = np.where(mask, -np.inf, predicted_matrix)\n",
        "\n",
        "    # Use argsort to get the indices of the top k predictions after masking\n",
        "    top_k_indices = np.argsort(masked_predictions, axis=1)[:, ::-1][:, :k]\n",
        "\n",
        "    # Extract relevant items in ground truth corresponding to the top k predictions\n",
        "    relevant_items = ground_truth_matrix[np.arange(ground_truth_matrix.shape[0])[:, None], top_k_indices]\n",
        "\n",
        "    # Calculate precision as the number of relevant items divided by k\n",
        "    precision_scores = np.sum(relevant_items, axis=1) / k\n",
        "\n",
        "    # Return the average precision\n",
        "    return np.mean(precision_scores)\n",
        "\n",
        "\n",
        "\n",
        "def recall_at_k(predicted_matrix, ground_truth_matrix, input_matrix, k):\n",
        "    # Mask the predictions where the input matrix has 1s (already in the playlist)\n",
        "    mask = input_matrix == 1\n",
        "    masked_predictions = np.where(mask, -np.inf, predicted_matrix)\n",
        "\n",
        "    # Get the indices of the top k predictions for each row after masking\n",
        "    top_k_indices = np.argsort(masked_predictions, axis=1)[:, -k:][:, ::-1]\n",
        "\n",
        "    # Gather the relevant items in ground truth corresponding to top k predictions\n",
        "    relevant_items = ground_truth_matrix[np.arange(ground_truth_matrix.shape[0])[:, None], top_k_indices]\n",
        "\n",
        "    # Calculate the recall for each playlist\n",
        "    total_relevant = np.sum(ground_truth_matrix, axis=1)  # Total relevant items per playlist\n",
        "\n",
        "    # Avoid division by zero: mask rows with no relevant items\n",
        "    recall_scores = np.sum(relevant_items, axis=1) / np.maximum(total_relevant, 1)\n",
        "\n",
        "    # Return the mean recall, ignoring rows with no relevant items\n",
        "    return np.mean(recall_scores[total_relevant > 0])\n",
        "\n",
        "\n",
        "\n",
        "def mean_reciprocal_rank(predicted_matrix, ground_truth_matrix, input_matrix):\n",
        "    reciprocal_ranks = []\n",
        "\n",
        "    # Iterate over each playlist (row in the matrix)\n",
        "    for pred_row, true_row, input_row in zip(predicted_matrix, ground_truth_matrix, input_matrix):\n",
        "        # Mask the predictions where the input matrix has 1s (already in the playlist)\n",
        "        mask = input_row == 1\n",
        "        masked_predictions = np.where(mask, -np.inf, pred_row)\n",
        "\n",
        "        # Get the indices sorted by predicted scores in descending order\n",
        "        sorted_indices = np.argsort(masked_predictions)[::-1]\n",
        "\n",
        "        # Find the rank of the first relevant item\n",
        "        found_relevant = False\n",
        "        for rank, index in enumerate(sorted_indices, start=1):\n",
        "            if true_row[index] == 1:  # If the item is relevant in the ground truth\n",
        "                reciprocal_ranks.append(1 / rank)\n",
        "                found_relevant = True\n",
        "                break\n",
        "\n",
        "        # If no relevant items were found, append 0\n",
        "        if not found_relevant:\n",
        "            reciprocal_ranks.append(0)\n",
        "\n",
        "    # Return the mean of the reciprocal ranks\n",
        "    return np.mean(reciprocal_ranks)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X_DF2313G_f3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title evaluating functions definition\n",
        "def evaluate_model_k_tracks_removed_df(model, k, num_valid_files=10):\n",
        "  \"\"\"\n",
        "  evaluate model processing a slice of playlists, 200 playlist at time to avoid\n",
        "  colab cpu overflow\n",
        "  \"\"\"\n",
        "\n",
        "  precision_at_10 = np.zeros(num_valid_files)\n",
        "  precision_at_5 = np.zeros(num_valid_files)\n",
        "  precision_at_2 = np.zeros(num_valid_files)\n",
        "  precision_at_1 = np.zeros(num_valid_files)\n",
        "\n",
        "  recall_at_10 = np.zeros(num_valid_files)\n",
        "  recall_at_5 = np.zeros(num_valid_files)\n",
        "  recall_at_2 = np.zeros(num_valid_files)\n",
        "  recall_at_1 = np.zeros(num_valid_files)\n",
        "\n",
        "  mrr = np.zeros(num_valid_files)\n",
        "\n",
        "  for file_idx, filename in enumerate(shuffled_slices[num_training_files:num_training_files+num_valid_files]):\n",
        "    correct_playlists = np.zeros((1000, num_tracks))\n",
        "    p_counter = -1\n",
        "    if filename.startswith(\"mpd.slice.\") and filename.endswith(\".json\"):\n",
        "      filepath = os.path.join(data, filename)\n",
        "\n",
        "      with open(filepath, \"r\", encoding=\"utf-8\") as jsonfile:\n",
        "        cur_slice = json.load(jsonfile)\n",
        "\n",
        "      for playlist in cur_slice[\"playlists\"]:\n",
        "        p_counter += 1\n",
        "\n",
        "        for track in playlist[\"tracks\"]:\n",
        "          track_uri = track[\"track_uri\"][14:]\n",
        "\n",
        "          if track_uri in tracks:\n",
        "            t_idx = track_uri_to_idx[track_uri]\n",
        "\n",
        "            correct_playlists[p_counter, t_idx] = 1\n",
        "\n",
        "\n",
        "    incomplete_playlists = np.copy(correct_playlists)\n",
        "\n",
        "    # Turn exactly k ones to zeros per row\n",
        "    for row in incomplete_playlists:\n",
        "      # Get the indices of `1`s in the current row\n",
        "      one_indices = np.where(row == 1)[0]\n",
        "\n",
        "      if len(one_indices) >= k:\n",
        "        indices_to_zero = np.random.choice(one_indices, size=k, replace=False)\n",
        "        row[indices_to_zero] = 0\n",
        "\n",
        "    n_iter = 5\n",
        "\n",
        "    cur_precision_at_10 = [0 for _ in range(n_iter)]\n",
        "    cur_precision_at_5 = [0 for _ in range(n_iter)]\n",
        "    cur_precision_at_2 = [0 for _ in range(n_iter)]\n",
        "    cur_precision_at_1 = [0 for _ in range(n_iter)]\n",
        "\n",
        "    cur_recall_at_10 = [0 for _ in range(n_iter)]\n",
        "    cur_recall_at_5 = [0 for _ in range(n_iter)]\n",
        "    cur_recall_at_2 = [0 for _ in range(n_iter)]\n",
        "    cur_recall_at_1 = [0 for _ in range(n_iter)]\n",
        "\n",
        "    cur_mrr = [0 for _ in range(n_iter)]\n",
        "\n",
        "    size_batch = 1000 // n_iter\n",
        "\n",
        "    for iter in range(n_iter):\n",
        "      input_matrix_iter = incomplete_playlists[size_batch*iter:size_batch*(iter+1), :]\n",
        "      P_new = model.transform(input_matrix_iter)\n",
        "\n",
        "      # Predici la matrice ricostruita per le nuove playlist\n",
        "      predicted_matrix = np.dot(P_new, model.components_)\n",
        "\n",
        "      ground_truth_matrix_iter = correct_playlists[size_batch*iter:size_batch*(iter+1), :]\n",
        "\n",
        "      cur_precision_at_10[iter] = precision_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 10)\n",
        "      cur_precision_at_5[iter] = precision_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 5)\n",
        "      cur_precision_at_2[iter] = precision_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 2)\n",
        "      cur_precision_at_1[iter] = precision_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 1)\n",
        "\n",
        "      cur_recall_at_10[iter] = recall_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 10)\n",
        "      cur_recall_at_5[iter] = recall_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 5)\n",
        "      cur_recall_at_2[iter] = recall_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 2)\n",
        "      cur_recall_at_1[iter] = recall_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 1)\n",
        "\n",
        "      cur_mrr[iter] = mean_reciprocal_rank(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter)\n",
        "\n",
        "    precision_at_10[file_idx] = np.mean(cur_precision_at_10)\n",
        "    precision_at_5[file_idx] = np.mean(cur_precision_at_5)\n",
        "    precision_at_2[file_idx] = np.mean(cur_precision_at_2)\n",
        "    precision_at_1[file_idx] = np.mean(cur_precision_at_1)\n",
        "    recall_at_10[file_idx] = np.mean(cur_recall_at_10)\n",
        "    recall_at_5[file_idx] = np.mean(cur_recall_at_5)\n",
        "    recall_at_2[file_idx] = np.mean(cur_recall_at_2)\n",
        "    recall_at_1[file_idx] = np.mean(cur_recall_at_1)\n",
        "    mrr[file_idx] = np.mean(cur_mrr)\n",
        "\n",
        "  print(\"Precision@10 = \",np.mean(precision_at_10))\n",
        "  print(\"Precision@5 = \",np.mean(precision_at_5))\n",
        "  print(\"Precision@2 = \",np.mean(precision_at_2))\n",
        "  print(\"Precision@1 = \",np.mean(precision_at_1))\n",
        "\n",
        "  print(\"Recall@10 = \",np.mean(recall_at_10))\n",
        "  print(\"Recall@5 = \",np.mean(recall_at_5))\n",
        "  print(\"Recall@2 = \",np.mean(recall_at_2))\n",
        "  print(\"Recall@1 = \",np.mean(recall_at_1))\n",
        "\n",
        "  print(\"MRR = \", np.mean(mrr))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_model_k_tracks_per_playlist(model, k, num_valid_files=10):\n",
        "  \"\"\"\n",
        "  evaluate model processing a slice of playlists, 200 playlist at time to avoid\n",
        "  colab cpu overflow\n",
        "  \"\"\"\n",
        "\n",
        "  # num_valid_files = 1000 - num_training_files\n",
        "  precision_at_10 = np.zeros(num_valid_files)\n",
        "  precision_at_5 = np.zeros(num_valid_files)\n",
        "  precision_at_2 = np.zeros(num_valid_files)\n",
        "  precision_at_1 = np.zeros(num_valid_files)\n",
        "\n",
        "  recall_at_10 = np.zeros(num_valid_files)\n",
        "  recall_at_5 = np.zeros(num_valid_files)\n",
        "  recall_at_2 = np.zeros(num_valid_files)\n",
        "  recall_at_1 = np.zeros(num_valid_files)\n",
        "\n",
        "  mrr = np.zeros(num_valid_files)\n",
        "\n",
        "  for file_idx, filename in enumerate(shuffled_slices[num_training_files:num_training_files+num_valid_files]):\n",
        "    correct_playlists = np.zeros((1000, num_tracks))\n",
        "    p_counter = -1\n",
        "    if filename.startswith(\"mpd.slice.\") and filename.endswith(\".json\"):\n",
        "      filepath = os.path.join(data, filename)\n",
        "\n",
        "      with open(filepath, \"r\", encoding=\"utf-8\") as jsonfile:\n",
        "        cur_slice = json.load(jsonfile)\n",
        "\n",
        "      for playlist in cur_slice[\"playlists\"]:\n",
        "        p_counter += 1\n",
        "\n",
        "        for track in playlist[\"tracks\"]:\n",
        "          track_uri = track[\"track_uri\"][14:]\n",
        "\n",
        "          if track_uri in tracks:\n",
        "            t_idx = track_uri_to_idx[track_uri]\n",
        "\n",
        "            correct_playlists[p_counter, t_idx] = 1\n",
        "\n",
        "\n",
        "    incomplete_playlists = np.copy(correct_playlists)\n",
        "\n",
        "    for row in incomplete_playlists:\n",
        "      one_indexes = np.where(row == 1)[0]\n",
        "\n",
        "      if len(one_indexes) >= k:\n",
        "        indices_to_zero = np.random.choice(one_indexes, size=(len(one_indexes)-k), replace=False)\n",
        "        row[indices_to_zero] = 0\n",
        "\n",
        "    n_iter = 5\n",
        "\n",
        "    cur_precision_at_10 = [0 for _ in range(n_iter)]\n",
        "    cur_precision_at_5 = [0 for _ in range(n_iter)]\n",
        "    cur_precision_at_2 = [0 for _ in range(n_iter)]\n",
        "    cur_precision_at_1 = [0 for _ in range(n_iter)]\n",
        "\n",
        "    cur_recall_at_10 = [0 for _ in range(n_iter)]\n",
        "    cur_recall_at_5 = [0 for _ in range(n_iter)]\n",
        "    cur_recall_at_2 = [0 for _ in range(n_iter)]\n",
        "    cur_recall_at_1 = [0 for _ in range(n_iter)]\n",
        "\n",
        "    cur_mrr = [0 for _ in range(n_iter)]\n",
        "\n",
        "    size_batch = 1000 // n_iter\n",
        "\n",
        "    for iter in range(n_iter):\n",
        "      input_matrix_iter = incomplete_playlists[size_batch*iter:size_batch*(iter+1), :]\n",
        "      P_new = model.transform(input_matrix_iter)\n",
        "\n",
        "      # Predici la matrice ricostruita per le nuove playlist\n",
        "      predicted_matrix = np.dot(P_new, model.components_)\n",
        "\n",
        "      ground_truth_matrix_iter = correct_playlists[size_batch*iter:size_batch*(iter+1), :]\n",
        "\n",
        "      cur_precision_at_10[iter] = precision_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 10)\n",
        "      cur_precision_at_5[iter] = precision_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 5)\n",
        "      cur_precision_at_2[iter] = precision_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 2)\n",
        "      cur_precision_at_1[iter] = precision_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 1)\n",
        "\n",
        "      cur_recall_at_10[iter] = recall_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 10)\n",
        "      cur_recall_at_5[iter] = recall_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 5)\n",
        "      cur_recall_at_2[iter] = recall_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 2)\n",
        "      cur_recall_at_1[iter] = recall_at_k(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter, 1)\n",
        "\n",
        "      cur_mrr[iter] = mean_reciprocal_rank(predicted_matrix, ground_truth_matrix_iter, input_matrix_iter)\n",
        "\n",
        "    precision_at_10[file_idx] = np.mean(cur_precision_at_10)\n",
        "    precision_at_5[file_idx] = np.mean(cur_precision_at_5)\n",
        "    precision_at_2[file_idx] = np.mean(cur_precision_at_2)\n",
        "    precision_at_1[file_idx] = np.mean(cur_precision_at_1)\n",
        "    recall_at_10[file_idx] = np.mean(cur_recall_at_10)\n",
        "    recall_at_5[file_idx] = np.mean(cur_recall_at_5)\n",
        "    recall_at_2[file_idx] = np.mean(cur_recall_at_2)\n",
        "    recall_at_1[file_idx] = np.mean(cur_recall_at_1)\n",
        "    mrr[file_idx] = np.mean(cur_mrr)\n",
        "\n",
        "  print(\"Precision@10 = \",np.mean(precision_at_10))\n",
        "  print(\"Precision@5 = \",np.mean(precision_at_5))\n",
        "  print(\"Precision@2 = \",np.mean(precision_at_2))\n",
        "  print(\"Precision@1 = \",np.mean(precision_at_1))\n",
        "\n",
        "  print(\"Recall@10 = \",np.mean(recall_at_10))\n",
        "  print(\"Recall@5 = \",np.mean(recall_at_5))\n",
        "  print(\"Recall@2 = \",np.mean(recall_at_2))\n",
        "  print(\"Recall@1 = \",np.mean(recall_at_1))\n",
        "\n",
        "  print(\"MRR = \", np.mean(mrr))"
      ],
      "metadata": {
        "id": "EApnpa-aLSX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K1 = [0, 2, 5, 15, 30]\n",
        "K2 = [2, 5, 15, 30]\n",
        "\n",
        "for k in K1:\n",
        "  print(f\"\\n Validation Metrics Removing {k} songs:\")\n",
        "  evaluate_model_k_tracks_removed_df(svd_model, k, 2)\n",
        "  print()\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "for k in K2:\n",
        "  print(f\"\\n Validation Metrics Keeping {k} songs per playlist:\")\n",
        "  evaluate_model_k_tracks_per_playlist(svd_model, k, 2)\n",
        "  print()\n"
      ],
      "metadata": {
        "id": "4SuVi9BI_zQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Language Model Approach"
      ],
      "metadata": {
        "id": "o8buF6l80anu"
      }
    }
  ]
}